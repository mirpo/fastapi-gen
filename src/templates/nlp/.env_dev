SUMMARIZE_MODEL="t5-small"      # "facebook/bart-large-cnn"
NER_MODEL="dslim/bert-base-NER" # "dslim/bert-large-NER"
TEXT_GENERATION_MODEL="gpt2"    # "mosaicml/mpt-7b-instruct" or "tiiuae/falcon-7b"
TEXT_GENERATION_TEMPERATURE=0.5 # controls the randomness of language model. 0.1 to reduce creativity, with 1.0 you cat get really crazy and weird results.
TEXT_GENERATION_DO_SAMPLE=True  # enables randomness of language model.
