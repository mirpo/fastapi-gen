# path to the local model
LLM_MODEL="./models/SmolLM2-135M-Instruct-Q4_K_M.gguf"

# controls the randomness of language model.
# 0.1 - to reduce creativity.
# 1.0 - you get more random results.
LLM_TEMPERATURE=0.3

# Model performance settings (optimized for fast tests)
LLM_MAX_TOKENS=5
LLM_N_CTX=128
LLM_N_THREADS=4
LLM_N_GPU_LAYERS=0
LLM_VERBOSE=False
LLM_SEED=42
