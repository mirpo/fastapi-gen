[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llama-fastapi-app"
version = "0.1.0"
description = "FastAPI application with local LLM (llama.cpp)"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  "fastapi==0.119.1",
  "uvicorn==0.38.0",
  "llama-cpp-python==0.3.16",
  "pydantic-settings==2.11.0",
]

[dependency-groups]
dev = [
  "ruff==0.14.1",
  "pytest==8.4.2",
  "httpx==0.28.1",
]

[project.scripts]
start = "uvicorn llama_app.main:app --reload --host 127.0.0.1 --port 8000"
lint = "ruff check src tests"
lint-fix = "ruff check --fix src tests && ruff format src tests"
test = "pytest -vv"
download-model = "python -c 'from llama_app.main import download_model; download_model()'"

[tool.ruff]
target-version = "py311"
line-length = 120

[tool.ruff.lint]
select = ["E", "F", "I"]
